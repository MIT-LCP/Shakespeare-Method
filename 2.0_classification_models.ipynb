{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Classification\n",
    "## Supervised classification models for the deduplicated vectorized data \n",
    " - test train split\n",
    " - run model, get scores\n",
    " - plot roc auc for multiple models\n",
    " - pull top 5000 features based on coef or log proba from chosen model\n",
    " - make matrix based on above for further feature selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import  LogisticRegression, SGDClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc,  classification_report, make_scorer, accuracy_score\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import time\n",
    "import math\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.sparse import csr_matrix, vstack\n",
    "\n",
    "from importlib_metadata import version\n",
    "\n",
    "\n",
    "libraries = ['pandas','numpy','scikit-learn', 'scipy','matplotlib']\n",
    "print('last ran: ',datetime.now() )\n",
    "print(\"Python Version:\", sys.version[0:7])\n",
    "print( \"operating system:\", sys.platform)\n",
    "\n",
    "for lib in libraries:\n",
    "    print(lib + ' version: ' + version(lib))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_unpickle(path):        \n",
    "    mat = []\n",
    "    for i in range(0,10):\n",
    "        with open(path+'textfeatures_mat'+str(i+1)+'.pickle', 'rb') as f:\n",
    "            mat.append(pickle.load(f,encoding='latin1'))\n",
    "    mat=vstack(mat)\n",
    "\n",
    "    q=[mat]\n",
    "    with open(path+'textfeatures_vocab.pickle', 'rb') as f:\n",
    "        vocab=pickle.load(f,encoding='latin1')\n",
    "        q.append(vocab)\n",
    "    with open(path+'textfeatures_id.pickle', 'rb') as f:\n",
    "        ids=pickle.load(f,encoding='latin1')\n",
    "        q.append(ids)\n",
    "    with open(path+'textfeatures_source.pickle', 'rb') as f:\n",
    "        source=pickle.load(f,encoding='latin1')\n",
    "        q.append(source)\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime = datetime.now()\n",
    "print (startTime)\n",
    "\n",
    "#load input data\n",
    "path =\"./\"\n",
    "path1 = \"LR/\"\n",
    "path2 = \"NB/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=feature_unpickle(path)\n",
    "XX = r[0]\n",
    "y = r[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stratified b/c we have unbalanced classes (more non-transfused than transfused),\n",
    "# and shuffle b/c the classe are grouped together in the matrix. This function will help us to get a balanced, random selection of each class into our test and train sections. \n",
    "rs = StratifiedShuffleSplit(n_splits=1, random_state=42, test_size=0.25, train_size=None)\n",
    "\n",
    "for train_index, test_index in rs.split(XX,y):\n",
    "    print('TRAIN:', train_index, \"TEST:\", test_index)\n",
    "\n",
    "X_train = XX[train_index,:]\n",
    "X_test = XX[test_index,:]\n",
    "\n",
    "y_train = y[train_index]\n",
    "y_test = y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = LabelEncoder()\n",
    "y_test1 = m.fit_transform(y_test)\n",
    "m = LabelEncoder()\n",
    "y_train1 = m.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.summer):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=30)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, fontsize=20)\n",
    "    plt.yticks(tick_marks, classes, fontsize=20)\n",
    "    \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", \n",
    "                 color=\"white\" if cm[i, j] < thresh else \"black\", fontsize=40)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label', fontsize=30)\n",
    "    plt.xlabel('Predicted label', fontsize=30)\n",
    "    \n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBmodel = naive_bayes.MultinomialNB()\n",
    "NBmodel.fit(X_train, y_train)\n",
    "# save model\n",
    "with open('NBmodel.pickle', 'wb') as picklefile:  \n",
    "    pickle.dump(NBmodel,picklefile)\n",
    "#with open('NB_model.pickle', 'rb') as f:  \n",
    "  #  NBmodel = pickle.load(f,encoding='latin1')\n",
    "print (\"naive bayes Scoring on test set\")\n",
    "Y_pred = NBmodel.predict(X_test)\n",
    "cr = classification_report(y_test, Y_pred)\n",
    "print( cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, Y_pred)\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "plot = plot_confusion_matrix(cm, classes=['Non','Transfused'], normalize=False)\n",
    "plt.savefig(\"NB_confusion_matrix.svg\")\n",
    "plt.show()\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LRmodel = LogisticRegression(verbose=1)\n",
    "LRmodel.fit(X_train, y_train)\n",
    "#save model\n",
    "with open('LRmodel.pickle', 'wb') as picklefile:  \n",
    "    pickle.dump(LRmodel,picklefile)\n",
    "#load model\n",
    "#with open('LRmodel.pickle', 'rb') as f:  \n",
    " #   LRmodel = pickle.load(f,encoding='latin1')\n",
    "\n",
    "print( \"Logistic regression Scoring on test set\")\n",
    "LR_Y_pred = LRmodel.predict(X_test)\n",
    "cr = classification_report(y_test, LR_Y_pred)\n",
    "print (cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, LR_Y_pred)\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "plot = plot_confusion_matrix(cm, classes=['Non','Transfused'], normalize=False)\n",
    "plt.savefig(\"LR_confusion_matrix.svg\")\n",
    "plt.show()\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_forest_model = RandomForestClassifier(n_estimators=10)\n",
    "r_forest_model.fit(X_train, y_train)\n",
    "\n",
    "# save model\n",
    "with open('r_forest_model.pickle', 'wb') as picklefile:  \n",
    "    pickle.dump(r_forest_model,picklefile)\n",
    "\n",
    "print (\"Random Forest Scoring on test set\")\n",
    "Y_pred = r_forest_model.predict(X_test)\n",
    "cr = classification_report(y_test, Y_pred)\n",
    "print (cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats=r[4]\n",
    "feature_names = [feats[i] for i in r_forest_model.feature_importances_]\n",
    "\n",
    "feature_importances = pd.DataFrame(r_forest_model.feature_importances_,\n",
    "                                   index = feature_names,\n",
    "                                columns=['importance']).sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SGDc_model = SGDClassifier(loss='modified_huber', penalty='l2',\\\n",
    "                      alpha=1e-3, random_state=42,\\\n",
    "                      max_iter=100, tol=None, shuffle=True)\n",
    "    #loss=\"modified_huber\", penalty=\"l2\",max_iter=100, shuffle=True)\n",
    "SGDc_model.fit(X_train, y_train)\n",
    "# save model\n",
    "with open('SGDc_model.pickle', 'wb') as picklefile:  \n",
    "    pickle.dump(SGDc_model,picklefile)\n",
    "\n",
    "print (\"SVM Scoring on test set\")\n",
    "Y_pred = SGDc_model.predict(X_test)\n",
    "cr = classification_report(y_test, Y_pred)\n",
    "print (cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNNc_model = KNeighborsClassifier(n_neighbors=5)\n",
    "KNNc_model.fit(X_train, y_train)\n",
    "# save model\n",
    "with open('KNNc_model.pickle', 'wb') as picklefile:  \n",
    "    pickle.dump(KNNc_model,picklefile)\n",
    "\n",
    "print (\"KNN Scoring on test set\")\n",
    "Y_pred = KNNc_model.predict(X_test)\n",
    "cr = classification_report(y_test, Y_pred)\n",
    "print (cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model = DummyClassifier(strategy='constant', constant=0)\n",
    "dummy_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot roc curves "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_plot(X_test, y_test):\n",
    "\n",
    "    def get_roc(model, X_test, y_test):\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = model.predict_proba(X_test)\n",
    "        score = round(model.score(X_test,y_test), 2)\n",
    "        fpr, tpr, _ = roc_curve(y_test.ravel(), y_pred_proba[:,1])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        return fpr, tpr, roc_auc, score\n",
    "\n",
    "    sns.set_style('white')\n",
    "    sns.set_context(\"talk\")\n",
    "    fig0 = plt.figure(figsize=(15,8), dpi=100);\n",
    "    plt.plot([0, 1], [0, 1], lw=2, color = 'black' , linestyle='--')\n",
    "    \n",
    "    fpr1, tpr1, roc_auc1,score1 = get_roc(NBmodel,  X_test,  y_test)\n",
    "    plt.plot(fpr1, tpr1, lw=2, color = 'brown', label='Multinomial NB area=%0.2f,accuracy={}'.format(score1) % roc_auc1)\n",
    "    \n",
    "    fpr2, tpr2, roc_auc2, score2 = get_roc(LRmodel, X_test, y_test)\n",
    "    plt.plot(fpr2, tpr2, lw=2, color = 'darkviolet', label='Log Reg area=%0.2f,accuracy={}'.format(score2) % roc_auc2)\n",
    "    \n",
    "    fpr5, tpr5, roc_auc5,score5 = get_roc(KNNc_model,  X_test,  y_test)\n",
    "    plt.plot(fpr5, tpr5, lw=2, color = 'darkgray', label='KNN area=%0.2f,accuracy={}'.format(score5)  % roc_auc5)\n",
    "    \n",
    "    fpr3, tpr3, roc_auc3,score3 = get_roc(SGDc_model, X_test,  y_test)\n",
    "    plt.plot(fpr3, tpr3, lw=2, color = 'green', label='SVM area=%0.2f,accuracy={}'.format(score3) % roc_auc3)\n",
    "    \n",
    "    fpr4, tpr4, roc_auc4,score4 = get_roc(r_forest_model,  X_test,  y_test)\n",
    "    plt.plot(fpr4, tpr4, lw=2, color = 'royalblue',label='Random Forest area=%0.2f,accuracy={}'.format(score4)% roc_auc4)\n",
    "    \n",
    "    fpr6, tpr6, roc_auc6,score6 = get_roc(dummy_model,  X_test,  y_test)\n",
    "    plt.plot(fpr6, tpr6, lw=2, color = 'black',label='Chance area=%0.2f,accuracy={}'.format(score6)% roc_auc6)\n",
    "    \n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    #plt.title('ROC {}'.format(model), fontsize=12)\n",
    "    #plt.title('ROC All Models', fontsize=12)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(path + \"roc_plot.svg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_plot(X_test, y_test1, NBmodel, LRmodel, KNNc_model, SGDc_model, r_forest_model, dummy_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 1000+ features (coefs)\n",
    "+ get coefs from the logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=time.strftime(\"%Y%m%d%H%m\",time.localtime())\n",
    "#coef = model.coef_.copy()\n",
    "features = zip(r[1],LRmodel.coef_[0])\n",
    "top = pd.DataFrame(features)#.sort_values(by=1, ascending=False).head(1500).sort_values(0)\n",
    "#top.to_html(path +'top_logit_1500_'+t+'.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_important_features(vectorizer, model, n=5):\n",
    "    index_to_word = r[1]#{v:k for k,v in r[1]}\n",
    "    \n",
    "    # loop for each class\n",
    "    classes ={}\n",
    "    for class_index in range(model.coef_.shape[0]):\n",
    "        word_importances = [(el, index_to_word[i]) for i,el in enumerate(model.coef_[class_index])]\n",
    "        sorted_coeff = sorted(word_importances, key = lambda x : x[0], reverse=True)\n",
    "        tops = sorted(sorted_coeff[:n], key = lambda x : x[0])\n",
    "        bottom = sorted_coeff[-n:]\n",
    "        classes[class_index] = {\n",
    "            'tops':tops,\n",
    "            'bottom':bottom\n",
    "        }\n",
    "    return classes\n",
    "\n",
    "importance = get_most_important_features(r[0], LRmodel, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_important_words(top_scores, top_words, bottom_scores, bottom_words, name):\n",
    "    y_pos = np.arange(len(top_words))\n",
    "    top_pairs = [(a,b) for a,b in zip(top_words, top_scores)]\n",
    "    top_pairs = sorted(top_pairs, key=lambda x: x[1])\n",
    "    \n",
    "    bottom_pairs = [(a,b) for a,b in zip(bottom_words, bottom_scores)]\n",
    "    bottom_pairs = sorted(bottom_pairs, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    top_words = [a[0] for a in top_pairs]\n",
    "    top_scores = [a[1] for a in top_pairs]\n",
    "    \n",
    "    bottom_words = [a[0] for a in bottom_pairs]\n",
    "    bottom_scores = [a[1] for a in bottom_pairs]\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 20))  \n",
    "\n",
    "    plt.subplot(121)\n",
    "    plt.barh(y_pos,bottom_scores, alpha=0.5)\n",
    "    plt.title('Non-Transfused', fontsize=20)\n",
    "    plt.yticks(y_pos, bottom_words, fontsize=14)\n",
    "    plt.suptitle('Key words', fontsize=16)\n",
    "    plt.xlabel('Importance', fontsize=20)\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.barh(y_pos,top_scores,  alpha=0.5)\n",
    "    plt.title('Transfused', fontsize=20)\n",
    "    plt.yticks(y_pos, top_words, fontsize=14)\n",
    "    plt.suptitle(name, fontsize=16)\n",
    "    plt.xlabel('Importance', fontsize=20)\n",
    "    \n",
    "    plt.subplots_adjust(wspace=0.8)\n",
    "    plt.savefig(path + path1 + \"top_bottom_plot.svg\")\n",
    "    plt.show()\n",
    "\n",
    "top_scores_p = [a[0] for a in importance[0]['tops']][4955:-1]\n",
    "top_words_p = [a[1] for a in importance[0]['tops']][4955:-1]\n",
    "bottom_scores_p = [a[0] for a in importance[0]['bottom']][4955:-1]\n",
    "bottom_words_p = [a[1] for a in importance[0]['bottom']][4955:-1]\n",
    "\n",
    "plot_important_words(top_scores_p, top_words_p, bottom_scores_p, bottom_words_p, \"Most important words for relevance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bottom_coef = pd.DataFrame(columns=['vocab','coef'])#,data=[top_words,top_scores])\n",
    "bottom_coef['vocab'] = [a[1] for a in importance[0]['bottom']]\n",
    "bottom_coef['coef'] = [a[0] for a in importance[0]['bottom']]\n",
    "bottom_coef.sort_values('coef',ascending=True).head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_scores = [a[0] for a in importance[0]['tops']]\n",
    "top_words = [a[1] for a in importance[0]['tops']]\n",
    "\n",
    "top_coef = pd.DataFrame(columns=['vocab','coef'])#,data=[top_words,top_scores])\n",
    "top_coef['vocab'] = top_words\n",
    "top_coef['coef'] = top_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(top_coef.shape)\n",
    "top_coef.sort_values('coef').tail(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_coef = top_coef.sort_values(by='coef',axis=0,ascending=False)\n",
    "top_coef.to_csv(path + path1 + 'top_logit_coef_5000.csv')\n",
    "    \n",
    "print ('create matrix for clustering')\n",
    "top_idx=[r[1].index(k) for k in top_coef['vocab'].values]\n",
    "\n",
    "r0= r[0].sorted_indices()\n",
    "\n",
    "tmat = r0.T[top_idx]\n",
    "\n",
    "print ('done making matrix')\n",
    "\n",
    "#below is input for 'Remove transfusion terms, Collapse dupes into largest n-gram.ipynb'\n",
    "\n",
    "out=[tmat,top_coef]\n",
    "with open('logits_top_5000_matrix.pickle','wb') as f:\n",
    "    pickle.dump(out,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOP 5000 features according to log probability\n",
    "- for the naive Bayes model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=time.strftime(\"%Y%m%d%H%m\",time.localtime())\n",
    "\n",
    "prob = pd.DataFrame(NBmodel.feature_log_prob_)\n",
    "prob=prob.transpose()\n",
    "prob.columns=NBmodel.classes_\n",
    "prob['vocab']=pd.Series(r[1])\n",
    "prob['ratio']=prob['transfusion']/prob['control']\n",
    "prob= prob.drop(['transfusion', 'control'], axis=1)\n",
    "\n",
    "top_all = prob.sort_values(by='ratio')\n",
    "top = prob.sort_values(by='ratio').head(5000)\n",
    "print(top_all.shape)\n",
    "top_all.head()\n",
    "\n",
    "top1k = prob.sort_values(by='ratio').head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save terms and ratios and model\n",
    "\n",
    "top_all.to_pickle('NB_terms_ratio_all.pkl')\n",
    "\n",
    "with open( 'NB_model.pickle','wb') as f:\n",
    "    pickle.dump(NBmodel,f)\n",
    "top.to_csv('top_5000_feat_'+t+'.csv', columns=['vocab','ratio'], index=False)\n",
    "top.to_pickle('top_5000_feat.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (prob.sort_values(by='ratio').head(500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create matrix for modeling\n",
    "- saves results into a sparse matrix for unsupervised models (LDA, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 5k \n",
    "top_idx=[r[1].index(k) for k in top['vocab'].values]\n",
    "r0= r[0].sorted_indices()\n",
    "tmat = r0.T[top_idx]\n",
    "tmat.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#below is input for 'Remove transfusion terms, Collapse dupes into largest n-gram.ipynb'\n",
    "out=[tmat,top]\n",
    "with open('NB_5000_matrix.pickle','wb') as f:\n",
    "    pickle.dump(out,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
