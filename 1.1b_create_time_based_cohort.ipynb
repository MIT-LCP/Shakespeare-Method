{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1b_create_time_based_cohort\n",
    "+ postgres = 9.4 (likely that this does not make much difference)\n",
    "\n",
    "### Create a table in Postgres of admissions (and corresponding notes) related to heparin time periods\n",
    "\n",
    "1.1.0 Import hadm_ids for which time key exists <br />\n",
    "1.1.1 Keep only adults from Carevue <br />\n",
    "1.1.2 Pull admissions that match the hadm_ids with time key <br />\n",
    "1.1.3 Pull admit times/ discharge times from admissions table <br />\n",
    "1.1.4 Save to a new table in posgres <br />\n",
    "1.1.5 Get notes for those admissions <br />\n",
    "1.1.6 Calculate which admissions have any leap days <br />\n",
    "1.1.7 Calculate and apply time shift to all dates to get true dates <br />\n",
    "1.1.8 Double check the time shifts are correct (compare deltas) <br />\n",
    "1.1.9 Make tables for notes in this study <br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only run this cell if you need to reset the connection to postgres database after an error\n",
    "conn.commit();\n",
    "cur.close();\n",
    "conn.close();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import libraries, connect to mimic database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from time import sleep\n",
    "import time\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine, update, event\n",
    "\n",
    "from importlib_metadata import version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PASSWORD = os.environ.get(\"PASSWORD\")\n",
    "USERNAME = os.environ.get(\"USERNAME\")\n",
    "POSTGRES_CONNECT = os.environ.get(\"POSTGRES_CONNECT\")\n",
    "POSTGRES_ENGINE = os.environ.get(\"POSTGRES_ENGINE\")\n",
    "\n",
    "conn = psycopg2.connect(POSTGRES_CONNECT)\n",
    "engine = create_engine(POSTGRES_ENGINE)\n",
    "\n",
    "cur = conn.cursor();\n",
    "cur.execute(\"\"\"SET search_path = mimiciii;\"\"\")\n",
    "\n",
    "libraries = ['pandas','sqlalchemy','psycopg2','tqdm']\n",
    "print('last ran: ',datetime.now() )\n",
    "print(\"Python Version:\", sys.version[0:7])\n",
    "print( \"operating system:\", sys.platform)\n",
    "\n",
    "for lib in libraries:\n",
    "    print(lib + ' version: ' + version(lib))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.0 import the hadmids where a time key exists\n",
    "+ year_key.csv is the file that contained the dates and hadm_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = pd.read_csv(path1 + 'year_key.csv')\n",
    "\n",
    "key['hadm_id'] = key['hadm_id'].astype(str)\n",
    "len(key) # number of keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 create a dictionary of keys and ids for our cohort\n",
    "+ get adult hadm_ids from the inputevents_cv_adult table\n",
    "+ keep only the hadm_ids that have a key in the year_key.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load hadm_ids from adult carevue inputs\n",
    "adult_ids = pd.read_sql(\"\"\" SELECT DISTINCT(hadm_id)\n",
    "FROM mimiciii.inputevents_cv_adult;\"\"\", engine)\n",
    "\n",
    "# drop nans\n",
    "adult_ids.dropna(inplace=True)\n",
    "\n",
    "adult_ids['hadm_id'] = adult_ids['hadm_id'].astype(int)\n",
    "adult_ids['hadm_id'] = adult_ids['hadm_id'].astype(str)\n",
    "print('number of adult carevue ids ' + str(len(adult_ids)))\n",
    "\n",
    "# get ids that are in both the key and the adult carevue inputs via an inner join\n",
    "adult_keys = key.merge(adult_ids, how='inner',on='hadm_id')\n",
    "print('number of adult carevue ids with a key ' + str(len(adult_keys)))\n",
    "\n",
    "key_ids = tuple(adult_keys.hadm_id.values)\n",
    "\n",
    "# make key dict\n",
    "key_dict = dict(zip(list(adult_keys['hadm_id'].astype(int)), list(adult_keys['year'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 load the data from the admissions table for ids in the key_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_q = \"\"\"\n",
    "SELECT *\n",
    "FROM mimiciii.admissions\n",
    "WHERE hadm_id IN {0}\"\"\"\n",
    "\n",
    "sql = sql_q.format(key_ids)\n",
    "df=pd.read_sql(sql, engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 Get admittimes/dischtimes for each hadm_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make keys for admittime and dischtime\n",
    "hadm_admit_key = dict(list(zip(list(df['hadm_id']), list(df['admittime']))))\n",
    "hadm_disch_key = dict(list(zip(list(df['hadm_id']), list(df['dischtime'])))) \n",
    "\n",
    "# add a true year column\n",
    "df['true_year'] = df['hadm_id'].map(key_dict)\n",
    "#create a new table of ids and year\n",
    "df_ids_times = df.loc[:,['hadm_id','true_year']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4 make a new table in postgres of hadm_ids and keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"\n",
    "DROP TABLE IF EXISTS mimiciii.cv_real_dates;\n",
    "\n",
    "CREATE TABLE mimiciii.cv_real_dates\n",
    "(hadm_id int,\n",
    "true_year int);\"\"\")\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save the data from our new table in posgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ids_times.to_sql('cv_real_dates', con=engine, if_exists='append', chunksize=1, index=False, schema='mimiciii')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.5 get notes\n",
    "+ put notes and note times for adult cv admissions into a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"\n",
    "DROP TABLE IF EXISTS mimiciii.adult_cv_notes;\n",
    "\n",
    "SELECT  B.*\n",
    "INTO mimiciii.adult_cv_notes\n",
    "    FROM mimiciii.noteevents B\n",
    "    WHERE B.hadm_id IN (\n",
    "            SELECT  x.hadm_id \n",
    "            FROM mimiciii.cv_real_dates x)\n",
    "            \n",
    "    AND B.iserror IS NULL\n",
    ";\"\"\")\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"SELECT COUNT(*), COUNT(DISTINCT hadm_id) FROM  mimiciii.adult_cv_notes;\"\"\")\n",
    "ncount=cur.fetchall()\n",
    "print( pd.DataFrame(ncount, columns=[ 'total notes count','admissions']).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.6 Calculate which admissions were on leap days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_df = pd.read_sql('SELECT * from mimiciii.adult_cv_notes', con=conn)\n",
    "\n",
    "# map values from key/admissions\n",
    "note_df['true_year'] = note_df['hadm_id'].map(key_dict)\n",
    "note_df['admittime'] = note_df['hadm_id'].map(hadm_admit_key)\n",
    "note_df['dischtime'] = note_df['hadm_id'].map(hadm_disch_key)\n",
    "\n",
    "# check if a leap day\n",
    "def leap_year_bool(row):\n",
    "    if row.month == 2:\n",
    "        if row.day == 29:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "# make columns to indicate if dates need leap year shift\n",
    "note_df['admit_shift'] = note_df['admittime'].apply(lambda x: leap_year_bool(x))\n",
    "note_df['disch_shift'] = note_df['dischtime'].apply(lambda x: leap_year_bool(x))\n",
    "note_df['chart_shift'] = note_df['chartdate'].apply(lambda x: leap_year_bool(x))\n",
    "\n",
    "# column to indicate any leap years in the note record\n",
    "note_df['any_leap'] = note_df['admit_shift'] + note_df['disch_shift'] + note_df['chart_shift'] \n",
    "\n",
    "# create dataframe for unique admissions (with all notes) aggregated, to check if any leap day in record\n",
    "time_shift = note_df.groupby('hadm_id', as_index=False).agg({\"any_leap\": \"sum\"})\n",
    "\n",
    "# mark admission as having any leap days in record\n",
    "time_shift['any_leap'] = time_shift['any_leap'].astype(bool).astype(int)\n",
    "\n",
    "# making column for leapyear time change\n",
    "timechange = {0: 0,\n",
    "             1: 364} # 364 days is divisible by 7, will preserve day of week\n",
    "\n",
    "time_shift['leap_shift'] = time_shift['any_leap'].map(timechange)\n",
    "\n",
    "time_shift['leap_shift'] = [timedelta(days = i) for i in time_shift['leap_shift']]\n",
    "\n",
    "# map the leapyear time change to df\n",
    "leap_dict = dict(zip(list(time_shift['hadm_id']), list(time_shift['leap_shift'])))\n",
    "\n",
    "note_df['leap_shift'] = note_df['hadm_id'].map(leap_dict)\n",
    "\n",
    "# applying the leap year shift to just admission date (apply this shift to all admission dates later)\n",
    "note_df['new_admittime'] = note_df['admittime'] - note_df['leap_shift']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.7 Apply the true times and time shifts to all dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make column for true year based on original years key\n",
    "note_df['true_year'] = note_df['hadm_id'].map(key_dict)\n",
    "\n",
    "# applying the true years to the (leap year corrected) admission dates\n",
    "admittime_list = list(note_df['new_admittime'])\n",
    "true_years_list =list(note_df['true_year'])\n",
    "admittime_true_list = []\n",
    "\n",
    "for i, k in zip(admittime_list, true_years_list):\n",
    "    try:\n",
    "        j = i.replace(year = k)\n",
    "    except:\n",
    "        j ='Error'\n",
    "    admittime_true_list.append(j)\n",
    "\n",
    "# making true admittime    \n",
    "note_df['true_admittime'] = admittime_true_list\n",
    "\n",
    "# calculating change between leap shifted admittime and true admittime\n",
    "note_df['master_shift'] = note_df['new_admittime'] - note_df['true_admittime']\n",
    "\n",
    "# apply the leap year shift and master shift to all other times\n",
    "note_df['true_dischtime'] = note_df['dischtime'] - note_df['leap_shift'] - note_df['master_shift']\n",
    "note_df['true_chartdate'] = note_df['chartdate'] - note_df['leap_shift'] - note_df['master_shift']\n",
    "note_df['true_charttime'] = note_df['charttime'] - note_df['leap_shift'] - note_df['master_shift']\n",
    "note_df['true_storetime'] = note_df['storetime'] - note_df['leap_shift'] - note_df['master_shift']\n",
    "\n",
    "# drop unnecessary columns\n",
    "note_df.drop(columns = ['admit_shift', 'disch_shift', 'chart_shift', 'any_leap',\n",
    "                  'new_admittime'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.8 Double Checking the Time Shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirming the time deltas match \n",
    "def check_time(row):\n",
    "    fake_admit_to_chart = note_df.loc[row, 'chartdate'] - note_df.loc[row, 'admittime']\n",
    "    fake_chart_to_disch = note_df.loc[row, 'dischtime'] - note_df.loc[row, 'chartdate']\n",
    "    fake_admit_to_disch = note_df.loc[row, 'dischtime'] - note_df.loc[row, 'admittime']\n",
    "    \n",
    "    real_admit_to_chart = note_df.loc[row, 'true_chartdate'] - note_df.loc[row, 'true_admittime']\n",
    "    real_chart_to_disch = note_df.loc[row, 'true_dischtime'] - note_df.loc[row, 'true_chartdate']\n",
    "    real_admit_to_disch = note_df.loc[row, 'true_dischtime'] - note_df.loc[row, 'true_admittime']\n",
    "    \n",
    "    if fake_admit_to_chart != real_admit_to_chart:\n",
    "        result = 'Error'\n",
    "    elif fake_chart_to_disch != real_chart_to_disch:\n",
    "        result = 'Error'\n",
    "    elif fake_admit_to_disch != real_admit_to_disch:\n",
    "        result = 'Error'\n",
    "    else:\n",
    "        result = 'Match'\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# apply function to dataframe\n",
    "note_df['check_time'] = [check_time(x) for x in note_df.index]\n",
    "\n",
    "# print the results - should show all 'Match'\n",
    "note_df['check_time'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.9 Adding a table for real dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding time shifts to table   \n",
    "df_ids_times = note_df.loc[:,['hadm_id','true_year', 'true_admittime', \n",
    "                        'true_dischtime']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"\n",
    "DROP TABLE IF EXISTS mimiciii.time_study_id_date;\n",
    "\n",
    "CREATE TABLE mimiciii.time_study_id_date\n",
    "(hadm_id int,\n",
    "true_year int,\n",
    "true_admittime timestamp,\n",
    "true_dischtime timestamp);\"\"\")\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ids_times.to_sql('time_study_id_date', con=engine, if_exists='append', chunksize=1, index=False, schema='mimiciii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"\n",
    "DROP TABLE IF EXISTS mimiciii.time_study_notes;\n",
    "\n",
    "CREATE TABLE mimiciii.time_study_notes\n",
    "(hadm_id int,\n",
    "chartdate timestamp,\n",
    "charttime timestamp,\n",
    "storetime timestamp,\n",
    "text varchar,\n",
    "true_year int,\n",
    "true_admittime timestamp,\n",
    "true_dischtime timestamp,\n",
    "true_chartdate timestamp,\n",
    "true_charttime timestamp,\n",
    "true_storetime timestamp);\"\"\")\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_df_save = note_df.loc[:,['hadm_id', 'chartdate', 'charttime', 'storetime', 'text', 'true_year', \n",
    "                     'true_admittime', 'true_dischtime', 'true_chartdate', 'true_charttime', 'true_storetime']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_df_save.to_sql('time_study_notes', con=engine, if_exists='append', chunksize=1, index=False, schema='mimiciii')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Up, Commit, and Close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit();\n",
    "cur.close();\n",
    "conn.close();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
